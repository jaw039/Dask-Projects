{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285a4873-ff33-4ff1-b7d2-0032254484fe",
   "metadata": {},
   "source": [
    "## <font color='red'> INSTRUCTIONS </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89957ed8-c2d1-4592-8821-88806390d1cc",
   "metadata": {},
   "source": [
    "<b> \n",
    "1. Write your code only in cells below the \"WRITE CODE BELOW\" title. Do not modify the code below the \"DO NOT MODIFY\" title. <br>\n",
    "2. The expected data types of the output answers for each question are given in the last cell through assertion statements. Your answers must match these expected output data types. Hint: Many of the answers need to be a Python dictionary. Consider methods like to_dict() to convert a Pandas Series to a dictionary. <br>\n",
    "3. The answers are then written to a JSON file named my_results_PA1.json. You can compare this with the provided expected output file \"expected_results_PA1.json\". <br>\n",
    "4. After you complete writing your code, click \"Kernel -> Restart Kernel and Run All Cells\" on the top toolbar. There should NOT be any syntax/runtime errors, otherwise points will be deducted. <br>\n",
    "5. For submitting your solution, first download your notebook by clicking \"File -> Download\". Rename the file as &ltTEAM_ID&gt.ipynb\" and upload to Canvas.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f7e94-c5b1-494c-8aab-832242527a4e",
   "metadata": {},
   "source": [
    "## <font color='red'> DO NOT MODIFY </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f3c8d7-690f-428b-982d-94265b4a7f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from dask.distributed import Client\n",
    "import ctypes\n",
    "import numpy as np\n",
    "\n",
    "def trim_memory() -> int:\n",
    "    \"\"\"\n",
    "    helps to fix any memory leaks.\n",
    "    \"\"\"\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    return libc.malloc_trim(0)\n",
    "\n",
    "client = Client(\"127.0.0.1:8786\")\n",
    "client.run(trim_memory)\n",
    "client = client.restart()\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6ac532-d64f-4659-9cc8-94481f48c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b6eb9-e5d7-423a-a0bc-7b86e6db1ab4",
   "metadata": {},
   "source": [
    "## <font color='blue'> WRITE CODE BELOW </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf416f4d-1782-4fa5-9b2b-b44aafd55934",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in the 'user_reviews.csv' and 'products.csv' files, perform your calculations and place the answers in variables ans1 - ans7.\n",
    "\n",
    "df_reviews = dd.read_csv(\n",
    "    \"user_reviews.csv\",\n",
    "    dtype={\n",
    "        \"reviewerID\": \"object\", \n",
    "        \"asin\": \"object\", \n",
    "        \"reviewerName\": \"object\",\n",
    "        \"helpful\": \"object\", \n",
    "        \"reviewText\": \"object\", \n",
    "        \"overall\": \"float64\",\n",
    "        \"summary\": \"object\", \n",
    "        \"unixReviewTime\": \"float64\", \n",
    "        \"reviewTime\": \"object\"\n",
    "    },\n",
    "    blocksize=\"64MB\"\n",
    ")\n",
    "df_products = dd.read_csv(\n",
    "    \"products.csv\",\n",
    "    dtype={\n",
    "        \"asin\": \"object\", \n",
    "        \"salesRank\": \"object\", \n",
    "        \"imUrl\": \"object\",\n",
    "        \"categories\": \"object\", \n",
    "        \"title\": \"object\", \n",
    "        \"description\": \"object\",\n",
    "        \"price\": \"float64\", \n",
    "        \"related\": \"object\", \n",
    "        \"brand\": \"object\"\n",
    "    },\n",
    "    blocksize=\"64MB\"\n",
    ")\n",
    "\n",
    "df_merged = df_reviews[['asin', 'overall']].merge(df_products[['asin', 'price']], \n",
    "                                       on='asin', how='left', indicator=True)\n",
    "\n",
    "ans1 = (df_reviews.isnull().mean() * 100).round(2)\n",
    "\n",
    "ans2 = (df_products.isnull().mean() * 100).round(2)\n",
    "\n",
    "desc = df_products['price'].describe()\n",
    "\n",
    "ans1, ans2, desc = dd.compute(ans1, ans2, desc)\n",
    "ans1 = ans1.to_dict()\n",
    "ans2 = ans2.to_dict()\n",
    "\n",
    "desc = desc.loc[['mean', 'std', 'min', 'max', '50%']]\n",
    "ans4 = {\n",
    "    'mean': desc['mean'],\n",
    "    'min': desc['min'],\n",
    "    'max': desc['max'],\n",
    "    'std': desc['std'],\n",
    "    'median': desc['50%']\n",
    "}\n",
    "\n",
    "price_rate = df_merged[['price', 'overall']].dropna().persist()\n",
    "\n",
    "avgPrice = desc['mean']\n",
    "\n",
    "price_rating = price_rate['overall'].mean()\n",
    "\n",
    "price_std = price_rate['overall'].std()\n",
    "\n",
    "avgRating, stdRating = dd.compute(price_rating, price_std)\n",
    "\n",
    "stdPrice = desc['std']\n",
    "cov = ((price_rate['price'] - avgPrice) * (price_rate['overall'] - avgRating)).mean()\n",
    "ans3 = float((cov/(stdPrice * stdRating)).round(2).compute())\n",
    "\n",
    "def helper(part):\n",
    "    def get_super(myStr):\n",
    "        strs = ast.literal_eval(myStr)\n",
    "        if strs and isinstance(strs, list) and isinstance(strs[0], list):\n",
    "            return strs[0][0]\n",
    "        return None\n",
    "    part['super_category'] = part['categories'].dropna().apply(get_super)\n",
    "    return part\n",
    "\n",
    "meta_var = df_products._meta.assign(super_category='object')\n",
    "\n",
    "df_products = df_products.map_partitions(helper, meta = meta_var)\n",
    "\n",
    "category_counts = df_products.groupby('super_category')['asin'].count(split_out=48).compute()\n",
    "\n",
    "ans5 = category_counts.sort_values(ascending=False).to_dict()\n",
    "ans5.pop(\"\", None)\n",
    "\n",
    "df_products = df_products.drop(columns = ['categories', 'super_category'], axis = 1).persist()\n",
    "\n",
    "dangling_exists = (df_merged['_merge'] == 'left_only').any().compute()\n",
    "\n",
    "ans6 = int(dangling_exists)\n",
    "\n",
    "#q7\n",
    "df_asin = df_products['asin'].dropna().persist()\n",
    "asin_set = set(df_asin.compute())\n",
    "    \n",
    "related = df_products['related'].dropna().repartition(npartitions=48).persist()\n",
    "ans7 = 0\n",
    "\n",
    "for part in related.to_delayed():\n",
    "    part_df = part.compute()\n",
    "    for rel in part_df:\n",
    "        myDict = ast.literal_eval(rel)\n",
    "        vals = myDict.values()\n",
    "        ids = [pid for lst in vals for pid in lst]\n",
    "        if any(pid not in asin_set for pid in ids):\n",
    "            ans7 = 1\n",
    "            break\n",
    "    if ans7 == 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d92954-28b3-4ad0-b7de-d8b8f4816c80",
   "metadata": {},
   "source": [
    "## <font color='red'> DO NOT MODIFY </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c438177d-8c4d-4871-bbc6-bea2f0a004b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0adca53b-b276-4297-8434-6c0e94810d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time = 230.16935181617737s\n"
     ]
    }
   ],
   "source": [
    "print(f\"execution time = {end-start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935be195-dcc9-4e97-911a-bae25e2a70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "assert type(ans1) == dict, f\"answer to question 1 must be a dictionary like {{'reviewerID':0.2, ..}}, got type = {type(ans1)}\"\n",
    "assert type(ans2) == dict, f\"answer to question 2 must be a dictionary like {{'asin':0.2, ..}}, got type = {type(ans2)}\"\n",
    "assert type(ans3) == float, f\"answer to question 3 must be a float like 0.8, got type = {type(ans3)}\"\n",
    "assert type(ans4) == dict, f\"answer to question 4 must be a dictionary like {{'mean':0.4,'max':0.6,'median':0.6...}}, got type = {type(ans4)}\"\n",
    "assert type(ans5) == dict, f\"answer to question 5 must be a dictionary, got type = {type(ans5)}\"         \n",
    "assert ans6 == 0 or ans6==1, f\"answer to question 6 must be 0 or 1, got value = {ans6}\" \n",
    "assert ans7 == 0 or ans7==1, f\"answer to question 7 must be 0 or 1, got value = {ans7}\" \n",
    "\n",
    "ans_dict = {\n",
    "    \"q1\": ans1,\n",
    "    \"q2\": ans2,\n",
    "    \"q3\": ans3,\n",
    "    \"q4\": ans4,\n",
    "    \"q5\": ans5,\n",
    "    \"q6\": ans6,\n",
    "    \"q7\": ans7,\n",
    "    \"runtime\": end-start\n",
    "}\n",
    "with open('my_results_PA1.json', 'w') as outfile: json.dump(ans_dict, outfile)         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
